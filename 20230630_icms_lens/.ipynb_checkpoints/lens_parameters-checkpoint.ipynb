{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Goal\n",
    "\n",
    "- 카메라의한 distortion종류\n",
    "- 카메라의 intrinsic, extrinsic properties 찾기\n",
    "- distortion을 카메라 properties이용해서 복원하기\n",
    "\n",
    "# 2. Basics\n",
    "\n",
    "1. 핀홀 카메라의 두가지 distortions\n",
    "\n",
    "**(1) Tangentia**:</br>\n",
    "- 렌즈가 이미지 평면과 완벽히 평행아닐 때</br>\n",
    "- 한쪽이 예상보다 가깝게 느껴지게함.</br>\n",
    "$x_{distorted} = [2p_1xy         + p_2(r^2+2x^2)] + x$</br>\n",
    "$y_{distorted} = [2p_1(r^2+2y^2) + p_2xy] + y$</br>\n",
    "    \n",
    "**(2) Radial** : </br>\n",
    "- 직선을 곡선으로 보이게함.</br>\n",
    "- 카메라 중심에서 멀수록 심해짐.</br>\n",
    "$x_{distorted} = (1+k_1r^2+k_2r^4+k_3r^6) x$</br>\n",
    "$y_{distorted} = (1+k_1r^2+k_2r^4+k_3r^6) y$\n",
    "\n",
    "<span style =\"color:red\">\n",
    "$\\rightarrow$ 총 5개의 파라미터를 찾아야함 : Distortion Coeff. = {$p_1,p_2,k_1,k_2,k_3$}\n",
    "</span>\n",
    "    \n",
    "**(3) Intrinsic** : </br>\n",
    "- 카메라 자체의 특징으로  focal length ($f_x, f_y$)와 optical 센터 ($c_x, c_y$)를 포함한다.</br>\n",
    "- focal length, optical center는 다음의 3x3 카메라 매트릭스를 구성한다.</br>\n",
    "- 카메라 매트릭스는 같은 카메라로 찍은 이미지들에 공통으로 쓰일 수 있다.</br>\n",
    "            \n",
    "$camera\\; matrix = \\begin{bmatrix}\n",
    "f_x & 0 & c_x\\\\\n",
    "0 & f_y & c_y\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$</br>\n",
    "       \n",
    "       \n",
    "**(4) Extrinsic** : </br>\n",
    "- 회전, 선형이동 등의 3D 좌표변환에 해당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Method\n",
    "\n",
    "- 보정하는 방법: 알고있는 패턴(체스보드)의 샘플이미지 10개이상 준비, 알고있는 상대적 위치등을 이용하여 파라미터들을 찾는다.\n",
    "- opencv에서 스보드 이미지들로 파라미터 찾고, 보정하는 방법을 알아본다.\n",
    "\n",
    "- (1) 중요한 입력데이터 : 3D위치(object points), 2D위치(image points) (두 검은 사각형이 만나는 위치의)\n",
    "- (2) 간단히 하기위해서 : 체스보드가 xy평면에 놓여있다라고 즉 Z=0이라고 가정하면 입력데이터는 2D위치로 간단화 된다.\n",
    "- (3) 스케일 : 체스보드 한 칸의 길이로 스케일링한다. 현 이미지파일속 체스보드 크기 모르니까 1로 normalize함.\n",
    "\n",
    "# 4. Setup\n",
    "\n",
    "- 체스판은 보통 8x8 squares, 7x7 internal corners로 이뤄져 있는데. </br>\n",
    "<span style=\"color:red\">- 여기서는 6x8 grid(checker_A3.pdf 참조) (square = 9x7)를 사용한다. </span>\n",
    "<img src=\"opencv_lens/opencv_lens_ex_grid.png\" width=300 >\n",
    "-(1) cv.findChessboardCorners() : </br>\n",
    "    - 함수에 grid정보를 입력하면 이미지에서 코너포인트와 패턴인식 유무를 반환한다. </br>\n",
    "    - 코너위치 순서는 LEFT$\\rightarrow$RIGHT, TOP$\\rightarrow$BOTTOM 을 따른다.\n",
    "-(2) 주의할 점 : </br>\n",
    "    - 모든 이미지에서 패턴이 찾아지는 것이 아니므로 패턴이 인식되는 이미지들로만 파라미터 찾는데 사용해야 한다.\n",
    "    - cv.findCircleGrid()로 체스판이 아닌 원형그리드의 이미지로도 가능하다.\n",
    "-(3) 코너를 찾은 다음? :</br>\n",
    "    - cv.cornerSubPix() : 정확도를 높이기 위해 사용\n",
    "    - cv.drawChessboardCorners() : 찾은 패턴 겹쳐그리기?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "(3, 30, 0.001)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import glob\n",
    "import json\n",
    "\n",
    "\n",
    "#############################\n",
    "#  Camera & Sensor info     #\n",
    "#############################\n",
    "\n",
    "#--------------case : EK640-------------\n",
    "#width = 640\n",
    "#height  = 480\n",
    "#speed_of_light = 3e8\n",
    "#fmod = 24\n",
    "#pixel_size_in_meter = 10e-6\n",
    "\n",
    "#case : SVM\n",
    "#width = 640\n",
    "#height = 480\n",
    "#speed_of_light = 3e8\n",
    "#fmod = 20\n",
    "#pixel_size_in_meter = 5e-6\n",
    "\n",
    "\n",
    "#icms\n",
    "width = 1920\n",
    "height = 1080\n",
    "\n",
    "\n",
    "print(cv2.TERM_CRITERIA_EPS)\n",
    "print(cv2.TERM_CRITERIA_MAX_ITER)\n",
    "ngridx = 8\n",
    "ngridy = 6\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "print(criteria)\n",
    "isSingle=True\n",
    "#isSingle=False\n",
    "isAll = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/pic00/', './data/pic01/', './data/pic02/', './data/pic03/', './data/pic04/', './data/pic05/', './data/pic06/', './data/pic07/', './data/pic08/', './data/pic09/', './data/pic10/', './data/pic11/', './data/pic12/']\n"
     ]
    }
   ],
   "source": [
    "#folder_data0 = \"/mnt/d/20230522_EK640_TAKE2/new08/13sets/\"\n",
    "folder_data0 = \"./data/\"\n",
    "folder_data = glob.glob(folder_data0+\"*/\")\n",
    "folder_data.sort()\n",
    "print(folder_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp = []\n",
    "for i in folder_data:\n",
    "    print (i)\n",
    "    if \"pic04\" in i or \"pic00\" in i or \"pic08\" in i:\n",
    "        continue\n",
    "    else:\n",
    "        temp.append(i)\n",
    "temp\n",
    "folder_data   = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 ./data/pic00/ WIN_20230630_12_35_33_Pro.jpg\n",
      "1 0 ./data/pic01/ WIN_20230630_12_39_23_Pro.jpg\n",
      "1 1 ./data/pic01/ WIN_20230630_12_39_37_Pro.jpg\n",
      "2 0 ./data/pic02/ WIN_20230630_12_40_30_Pro.jpg\n",
      "3 0 ./data/pic03/ WIN_20230630_12_41_22_Pro.jpg\n",
      "4 0 ./data/pic04/ WIN_20230630_12_42_11_Pro.jpg\n",
      "5 0 ./data/pic05/ WIN_20230630_12_43_29_Pro.jpg\n",
      "5 1 ./data/pic05/ WIN_20230630_12_43_39_Pro.jpg\n",
      "6 0 ./data/pic06/ WIN_20230630_12_47_45_Pro.jpg\n",
      "6 1 ./data/pic06/ WIN_20230630_12_48_05_Pro.jpg\n",
      "7 0 ./data/pic07/ WIN_20230630_12_49_05_Pro.jpg\n",
      "8 0 ./data/pic08/ WIN_20230630_12_49_41_Pro.jpg\n",
      "8 1 ./data/pic08/ WIN_20230630_12_50_08_Pro.jpg\n",
      "9 0 ./data/pic09/ WIN_20230630_12_50_35_Pro.jpg\n",
      "10 0 ./data/pic10/ WIN_20230630_12_50_54_Pro.jpg\n",
      "10 1 ./data/pic10/ WIN_20230630_12_51_43_Pro.jpg\n",
      "11 0 ./data/pic11/ WIN_20230630_12_52_20_Pro.jpg\n",
      "12 0 ./data/pic12/ WIN_20230630_12_52_34_Pro.jpg\n"
     ]
    }
   ],
   "source": [
    "folder_data = np.array(folder_data)\n",
    "paths = []\n",
    "for folder in folder_data:\n",
    "    temp = glob.glob(folder+\"*.jpg\")\n",
    "    temp.sort()\n",
    "    paths.append(temp)\n",
    "fnames = []\n",
    "for pic in paths:\n",
    "    temp = []\n",
    "    for path in pic:\n",
    "        temp.append(path.split(\"/\")[-1])\n",
    "    fnames.append(temp)\n",
    "for i in range(len(fnames)):\n",
    "    for j in range(len(fnames[i])):\n",
    "        print(i,j,folder_data[i],fnames[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if isSingle is False:\n",
    "    minlen=1e5\n",
    "    for i in range(len(fnames)):\n",
    "        if len(fnames[i])<minlen:\n",
    "            minlen=len(fnames[i])\n",
    "else:\n",
    "    minlen = 1\n",
    "print(minlen)\n",
    "bad_samples=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "No corners found : [0][0]('./data/pic00/', 'WIN_20230630_12_35_33_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [3][0]('./data/pic03/', 'WIN_20230630_12_41_22_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [4][0]('./data/pic04/', 'WIN_20230630_12_42_11_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [5][0]('./data/pic05/', 'WIN_20230630_12_43_29_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [5][1]('./data/pic05/', 'WIN_20230630_12_43_39_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [6][0]('./data/pic06/', 'WIN_20230630_12_47_45_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [6][1]('./data/pic06/', 'WIN_20230630_12_48_05_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [7][0]('./data/pic07/', 'WIN_20230630_12_49_05_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [8][0]('./data/pic08/', 'WIN_20230630_12_49_41_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [8][1]('./data/pic08/', 'WIN_20230630_12_50_08_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [9][0]('./data/pic09/', 'WIN_20230630_12_50_35_Pro.jpg')\n",
      "\n",
      "\n",
      "No corners found : [10][1]('./data/pic10/', 'WIN_20230630_12_51_43_Pro.jpg')\n"
     ]
    }
   ],
   "source": [
    "pt_obj = np.zeros([ngridy*ngridx,3],np.float32)\n",
    "#pt_obj[:,:2] = np.mgrid[0:ngridy,0:ngridx].T.reshape(-1,2)\n",
    "idx=0\n",
    "for i in range (ngridx):\n",
    "    for j in range (ngridy):\n",
    "        pt_obj[idx]=np.array([j,i,0])\n",
    "        idx+=1\n",
    "#pt_obj\n",
    "pts_obj = []\n",
    "pts_img = []\n",
    "for i in range(len(fnames)):\n",
    "    temp_bad = []\n",
    "    count=0\n",
    "    stride = 0\n",
    "    if len(fnames[i])>20:\n",
    "        stride = int(len(fnames[i])/15)\n",
    "    for j in range(0,len(fnames[i])):\n",
    "        img_org  = cv2.imread(folder_data[i]+fnames[i][j])\n",
    "        img = cv2.cvtColor(img_org,cv2.COLOR_BGR2GRAY)\n",
    "    #-------------------------------------------------------- (1) find corners\n",
    "        ret, corners_temp = cv2.findChessboardCorners(img,(ngridy,ngridx),None)\n",
    "        #ret, corners_temp = cv2.findChessboardCorners(img,(ngridy,ngridx),cv2.CALIB_CB_LARGER + cv2.CALIB_CB_EXHAUSTIVE + cv2.CALIB_CB_NORMALIZE_IMAGE)#None)\n",
    "        #ret, corners_temp = cv2.findChessboardCorners(img,(ngridy,ngridx),flags=cv2.CALIB_CB_NORMALIZE_IMAGE | cv2.CALIB_CB_EXHAUSTIVE)#cv2.CALIB_CB_EXHAUSTIVE | cv2.CALIB_CB_ACCURACY)#cv2.CALIB_USE_INTRINSIC_GUESS)\n",
    "        #ret, corners_temp,meta = cv2.findChessboardCornersSBWithMeta(img,(ngridy,ngridx),cv2.CALIB_CB_LARGER + cv2.CALIB_CB_EXHAUSTIVE + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    #-------------------------------------------------------- (2) disregard images with no corners found\n",
    "        if ret is False:\n",
    "            print(f\"\\n\\nNo corners found : [{i}][{j}]{folder_data[i],fnames[i][j]}\")\n",
    "            temp_bad.append([i,j,folder_data[i],fnames[i][j]])\n",
    "            #continue\n",
    "        else:\n",
    "            if count==minlen:\n",
    "                break\n",
    "            count+=1\n",
    "            #pts_obj.append(pt_obj)\n",
    "            #pts_img.append(corners)\n",
    "            #cv2.drawChessboardCorners(img_org,(ngridy,ngridx),corners,ret)\n",
    "\n",
    "    #-------------------------------------------------------- (3) find more accurate corners\n",
    "            pts_obj.append(pt_obj)\n",
    "            corners = cv2.cornerSubPix(img,corners_temp,(11,11),(-1,-1),criteria)\n",
    "            pts_img.append(corners)\n",
    "            cv2.drawChessboardCorners(img_org,(ngridy,ngridx),corners,ret)\n",
    "\n",
    "            cv2.imshow('img',img_org)\n",
    "            cv2.imwrite(f\"{folder_data[i]}LENS/corners_{fnames[i][j].split('.')[0]}.jpg\",img_org)\n",
    "            cv2.waitKey(1200)\n",
    "    bad_samples.append(temp_bad)\n",
    "cv2.destroyAllWindows()\n",
    "#print(f\"\\n\\n{13-len(bad_samples)} out of 13 are successful.\")\n",
    "#print(\"\\n----------------bad samples are ...-------------\\n\")\n",
    "#bad_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------./data/_zero passed.\n",
      "00] 00 \n",
      "01] 01 \n",
      "02] 01 \n",
      "-----------------./data/_zero passed.\n",
      "03] 00 \n",
      "-----------------./data/_zero passed.\n",
      "04] 00 \n",
      "-----------------./data/_zero passed.\n",
      "05] 00 \n",
      "-----------------./data/_zero passed.\n",
      "06] 00 \n",
      "-----------------./data/_zero passed.\n",
      "07] 00 \n",
      "-----------------./data/_zero passed.\n",
      "08] 00 \n",
      "-----------------./data/_zero passed.\n",
      "09] 00 \n",
      "10] 01 \n",
      "11] 01 \n",
      "12] 01 \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(bad_samples)):\n",
    "    if len(fnames[i])-len(bad_samples[i]) >=minlen:\n",
    "        passed = minlen\n",
    "    else:\n",
    "        passed = len(fnames[i])-len(bad_samples[i])\n",
    "        print(f\"-----------------{folder_data0}_zero passed.\")\n",
    "    print(f\"{i:02}] {passed:02} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result\n",
    "\n",
    "without cv2.cornerSubPix() | with cv2.cornerSubPix\n",
    "-|-\n",
    "<img src=\"./data/20230108_lens_parameter/IR_\" width=\"500\">|<img src=\"./out_subPix/wSub_out00.jpg\" width=\"500\">\n",
    "\n",
    "<span style = \"color:red\">\n",
    "# cornerSubPix() is more accurate!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calibration- method1\n",
    "\n",
    "- corners를 찾아서 pt_obj, pt_img를 모두 찾았다.\n",
    "- ready to jump into calibration!</br>\n",
    "\n",
    "(1) find parameters : **cv2.calibrateCamera()** : return</br> \n",
    "$^{1)}$camera matrix, </br>\n",
    "$^{2)}$ distortion coeff., </br>\n",
    "$^{3)}$ rotation&translation vectors</br>\n",
    "\n",
    "(2) refine the camera matrix : **cv2.getOptimalNewCameraMatrix()** : return  </br>\n",
    "$^{1)}$ NEW camera matrix, </br>\n",
    "$^{2)}$ ROI (helps to crop the image without blank or black fillings.</br>\n",
    "<span style = \"color:blue\">\n",
    "** if scaling parameter (alpha) = 0 : may remove some pixels</br>\n",
    "** if alpha=1 : it retains all pixels wiht some extra BLACK images.</br>\n",
    "</span>\n",
    "(3) undistort the image : **cv2.undistort()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, camera_matrix, distortion_coeff, vec_rot, vec_trans = cv2.calibrateCamera(pts_obj, pts_img, img.shape[::-1],None,None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fnames)):\n",
    "    if fnames[i] in bad_samples:\n",
    "        continue\n",
    "    for j in range(len(fnames[i])):\n",
    "        img_org  = cv2.imread(folder_data[i]+\"IR/\"+fnames[i][j])\n",
    "        img = cv2.cvtColor(img_org,cv2.COLOR_BGR2GRAY)\n",
    "        h,w = img.shape[:2]\n",
    "        NEW_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, distortion_coeff, (w,h),1,(w,h))\n",
    "        #out = cv2.undistort(img, camera_matrix, distortion_coeff, None, NEW_camera_matrix)\n",
    "        #x,y,w,h = roi\n",
    "        #out = out[y:y+h,x:x+w]\n",
    "        #print(out.shape)\n",
    "        mapx,mapy = cv2.initUndistortRectifyMap(camera_matrix,distortion_coeff,None,NEW_camera_matrix,(w,h),5)\n",
    "        out = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "        x,y,w,h = roi\n",
    "        out = out[y:y+h,x:x+w]\n",
    "        fout = folder_data[i]+\"/LENS/undistorted_\"+fnames[i][j].split('.')[0]+\".png\"\n",
    "        cv2.imwrite(fout,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original | undistorted\n",
    "-|-\n",
    "    <img src=\"./opencv_lens/left12.jpg\" height=\"300\">|<img src=\"./calibrated_undistorted_left12.png\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calibration- method2\n",
    "\n",
    "(1) find a mapping function : distorted image (original) $\\rightarrow$ undistorted image\n",
    "\n",
    "(2) remap "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#------------------------------------------(1) find a mapping function\n",
    "xmap,ymap = cv2.initUndistortRectifyMap(camera_matrix, distortion_coeff, None, NEW_camera_matrix, (w,h),5)\n",
    "#------------------------------------------(2) remap\n",
    "out2 = cv2.remap(test_img, xmap,ymap,cv2.INTER_LINEAR)\n",
    "\n",
    "#crop image\n",
    "x,y,w,h = roi\n",
    "out2 = out2[y:y+h,x:x+w]\n",
    "cv2.imwrite(\"out_calibration/calibrated_undistorted_left12_MAPPING.png\",out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original|after mapping remapping\n",
    "-|-\n",
    "<img src=\"./opencv_lens/left12.jpg\" height=\"300\"> | <img src=\"out_left12_MAPPING.png\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = cv2.imread(\"./out_calibration/calibrated_undistorted_left12_MAPPING.png\")\n",
    "b = cv2.imread(\"./out_calibration/calibrated_undistorted_left12.png\")\n",
    "print(b.shape)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reprojection Error\n",
    "\n",
    "- Reprojection 에러? 찾은 파라미터가 얼마나 정확한지 알아보는 방법임.\n",
    "- Reprojection error=0 가까울수록 더 적확하다.\n",
    "\n",
    "(1) 카메라 파라미터, distorion 계수, 회전/병진벡터/행렬이 주어졌을 때, 3D-pt_obj 를 2D-pt_img로 바꾸어야 한다. : **cv2.projectPoints()**\n",
    "\n",
    "(2) $||norm|| = ||transformation - corner finding||$\n",
    "\n",
    "(3) take mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_error = 0\n",
    "for i in range(len(pts_obj)):\n",
    "    \n",
    "    if fnames[i]==bad_samples:\n",
    "        continue\n",
    "#-------------------------------(1) 3D to 2D\n",
    "    pts_img_projected, _ = cv2.projectPoints(pts_obj[i],vec_rot[i],vec_trans[i],camera_matrix,distortion_coeff)\n",
    "#-------------------------------(2) absolute norm : 2D from previous, 2D RE projected from 3D\n",
    "    error = cv2.norm(pts_img[i],pts_img_projected,cv2.NORM_L2)/len(pts_img_projected)\n",
    "    mean_error +=error\n",
    "#-------------------------------(3) mean\n",
    "print(f\"\\nAverage Error : {mean_error/(len(pts_obj)-len(bad_samples))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save parameters as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = {}\n",
    "image[\"width\"]=width\n",
    "image[\"height\"]=height\n",
    "image[\"speed\"]=speed_of_light\n",
    "image[\"fmod\"]=fmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = {}\n",
    "lens['pixel_size_x'] = pixel_size_in_meter\n",
    "lens['pixel_size_y'] = pixel_size_in_meter\n",
    "lens['fx'] = camera_matrix[0][0]\n",
    "lens['fy'] = camera_matrix[1][1]\n",
    "lens['cx'] = camera_matrix[0][2]\n",
    "lens['cy'] = camera_matrix[1][2]\n",
    "lens['p1'] = distortion_coeff[0][0]\n",
    "lens['p2'] = distortion_coeff[0][1]\n",
    "lens['k1'] = distortion_coeff[0][2]\n",
    "lens['k2'] = distortion_coeff[0][3]\n",
    "lens['k3'] = distortion_coeff[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= {}\n",
    "result[\"image\"]=image\n",
    "result[\"lens\"]=lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "camID = folder_data0.split('/')[-3]\n",
    "with open(folder_data0  + camID + \"_\" + \"lens_parameters_single.json\",'w') as f:\n",
    "    json.dump(result,f,indent=4,sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pixel_size_x': 1e-05, 'pixel_size_y': 1e-05, 'fx': 791.0015623090314, 'fy': 794.2830181052844, 'cx': 317.8133454845565, 'cy': 250.4639830798254, 'p1': -0.3055802905160831, 'p2': -0.0784949815019355, 'k1': 0.0004253500076153936, 'k2': -0.0006628106808933912, 'k3': 0.5326128081008801}\n"
     ]
    }
   ],
   "source": [
    "print(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.910015623090315 7.9428301810528446\n"
     ]
    }
   ],
   "source": [
    "fx_mm = lens['fx']*lens['pixel_size_x']*1e3\n",
    "fy_mm = lens['fy']*lens['pixel_size_y']*1e3\n",
    "print(fx_mm, fy_mm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results[\"camera_matrix\"]=camera_matrix\n",
    "results[\"distortion_coeff\"] = distortion_coeff\n",
    "results[\"vec_rot\"] = vec_rot\n",
    "results[\"vec_trans\"] = vec_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nCamera Matrix = \\n{camera_matrix})\\n\")\n",
    "print(f\"Distortion Coefficients = \\n{distortion_coeff}\\n\")\n",
    "print(f\"Rotation Vector = \")\n",
    "for i in vec_rot:\n",
    "    print(i.T)\n",
    "print(f\"\\nTranslation Vector = \")\n",
    "for i in vec_trans:\n",
    "    print(i.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(folder_data0+\"lens_parameter\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########Use the parameters found previously \n",
    "print(folder_data0+\"lens_parameter.npy\")\n",
    "params = np.load(folder_data0+\"lens_parameter.npy\",allow_pickle=True)\n",
    "#folder_d =\"/mnt/d/iToF_data/20230130_allLED_ON/\"\n",
    "#test_im_file  = folder_d+\"IR/IR_DCS_frame_1675036697624.jpg\"\n",
    "#folder_d = \"/home/hyoyeonlee/iToF_calibration/data/20230131_resolution_newParam/\"\n",
    "#test_im_file  = \"/home/hyoyeonlee/iToF_calibration/data/20230131_resolution_newParam/IR/IR_DCS_frame_1675154703854.jpg\"\n",
    "folder_d = \"/mnt/d/iToF_data/20230207_resolution_target_more_flatten/\"\n",
    "test_im_files = glob.glob(folder_d+\"IR/IR_*.jpg\")\n",
    "test_im_files.sort()\n",
    "print (test_im_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_img_org = cv2.imread(\"/home/hyoyeonlee/iTOF_calibration/data/20230105_lens_parameter/IR/04.jpg\")\n",
    "#test_img_org = cv2.imread(\"/home/hyoyeonlee/iTOF_calibration/data/20230108_lens_parameter/IR/\"+fnames[0])\n",
    "count = 0\n",
    "for test_im_file in test_im_files:\n",
    "    test_img_org = cv2.imread(test_im_file)\n",
    "    test_img = cv2.cvtColor(test_img_org,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    h,w = test_img.shape[:2]\n",
    "\n",
    "    test_camera_matrix = params.item().get(\"camera_matrix\")\n",
    "    test_distortion_coeff = params.item().get(\"distortion_coeff\")\n",
    "    test_NEW_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(test_camera_matrix, test_distortion_coeff, (w,h),1,(w,h))\n",
    "\n",
    "    tmapx,tmapy = cv2.initUndistortRectifyMap(test_camera_matrix,test_distortion_coeff,None,test_NEW_camera_matrix,(w,h),5)\n",
    "    tout = cv2.remap(test_img,tmapx,tmapy,cv2.INTER_LINEAR)\n",
    "    x,y,w,h = roi\n",
    "    tout = tout[y:y+h,x:x+w]\n",
    "    tfout = folder_d+\"/LENS/OUT_\"+str(count)+\".png\"\n",
    "    cv2.imwrite(tfout,tout)\n",
    "    count+=1\n",
    "\n",
    "\n",
    "    ftest_input = folder_d+\"/LENS/input.jpg\"\n",
    "    #cv2.imwrite(ftest_input,test_img)\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.imshow(tout,cmap=\"gray\")\n",
    "    #print(f\" input image shape = {test_img.shape}\")\n",
    "    print(f\"output image shape = {tout.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.imshow(tout,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
